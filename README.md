# LIDAR
Expo sobre sensor LIDAR

![](https://github.com/mrJCOM123/LIDAR/blob/main/lidar1.jpg)
¿Qué es?
La primera vez que vimos un sensor LiDAR fue en el iPad Pro. Con el lanzamiento del iPhone 12 Pro y iPhone 13 Pro se sumó también a la familia iPhone. En el iPad Pro está enfocado a mejorar la realidad aumentada. Por otro lado, en el iPhone, mejora la realidad aumentada y también ayuda a la hora de hacer fotografías y vídeos.

¿Cómo funciona?
Un sensor LiDAR mide la distancia a través de lo que tarda un haz de luz en alcanzar un objeto y volver reflejado al sensor.

![](https://github.com/mrJCOM123/LIDAR/blob/main/lidar2.jpg)

¿Para qué sirve el sensor LiDAR en el iPhone?
El iPhone 12 Pro y iPhone 13 Pro usa el sensor LiDAR para crear un mapa de profundidad del espacio en el que te estás moviendo. Principalmente tiene dos utilidades: La realidad aumentada y la cámara. 
El escáner LiDAR en el iPhone reconoce al instante la superficie que tiene delante. Así, las apps de realidad aumentada analizan tu entorno en cuanto las abres. Por ejemplo, puedes colocar cosas de forma híper-realista, ya sea un sofá, una silla o una alfombra de forma virtual.

El sensor LIDAR también ayuda a tomar mejores fotos y videos
El escáner LiDAR en el iPhone trae muchas mejoras al sistema de cámaras. El enfoque automático es hasta seis veces más rápido en condiciones con poca luz. Seguro que te ha pasado, la escena está tan oscura que tienes que tocar varias veces la pantalla para conseguir enfocar lo que querías fotografiar. Como el sensor LiDAR sabe directamente lo que tiene enfrente, te enfoca todo automáticamente.
También, con el iPhone 12 Pro y iPhone 13 Pro, vas a poder hacer retratos en modo Noche. Gracias al nivel de detalle del mapa de profundidad que crea el LiDAR en el iPhone, se puede obtener un primer plano nítido sobre un fondo difuminado. Se captan todos los detalles y texturas, sin perder el realismo de los colores del fondo.
![](https://github.com/mrJCOM123/LIDAR/blob/main/lidar3.jpg)
